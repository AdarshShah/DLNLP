{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "from torch.nn import GRU, ModuleList, Linear\n",
    "from torch.nn.functional import sigmoid, softmax, relu\n",
    "from torch.optim import Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('/home/adarsh/DLNLP/spacy/glove_840b_300d')\n",
    "filepath = '/home/adarsh/DLNLP/datasets/Assignment2/dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      " 66%|██████▌   | 26286/40000 [03:19<01:44, 131.68it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/adarsh/DLNLP/Assignment2.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.64.18.48/home/adarsh/DLNLP/Assignment2.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__len__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.64.18.48/home/adarsh/DLNLP/Assignment2.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.64.18.48/home/adarsh/DLNLP/Assignment2.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m dataset \u001b[39m=\u001b[39m ReviewDataset(filepath, nlp)\n",
      "\u001b[1;32m/home/adarsh/DLNLP/Assignment2.ipynb Cell 3\u001b[0m in \u001b[0;36mReviewDataset.__init__\u001b[0;34m(self, filepath, nlp)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.64.18.48/home/adarsh/DLNLP/Assignment2.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnlp \u001b[39m=\u001b[39m nlp\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.64.18.48/home/adarsh/DLNLP/Assignment2.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m dataset \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(filepath)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.64.18.48/home/adarsh/DLNLP/Assignment2.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m docs \u001b[39m=\u001b[39m [ nlp(review) \u001b[39mfor\u001b[39;00m review \u001b[39min\u001b[39;00m tqdm(dataset[\u001b[39m'\u001b[39m\u001b[39mreview\u001b[39m\u001b[39m'\u001b[39m])]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.64.18.48/home/adarsh/DLNLP/Assignment2.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX \u001b[39m=\u001b[39m [ torch\u001b[39m.\u001b[39mstack([ torch\u001b[39m.\u001b[39mtensor(token\u001b[39m.\u001b[39mvector) \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m doc ]) \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m tqdm(docs) ]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.64.18.48/home/adarsh/DLNLP/Assignment2.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mY \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(np\u001b[39m.\u001b[39mwhere(dataset[\u001b[39m'\u001b[39m\u001b[39msentiment\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnegative\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m))\n",
      "\u001b[1;32m/home/adarsh/DLNLP/Assignment2.ipynb Cell 3\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.64.18.48/home/adarsh/DLNLP/Assignment2.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnlp \u001b[39m=\u001b[39m nlp\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.64.18.48/home/adarsh/DLNLP/Assignment2.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m dataset \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(filepath)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.64.18.48/home/adarsh/DLNLP/Assignment2.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m docs \u001b[39m=\u001b[39m [ nlp(review) \u001b[39mfor\u001b[39;00m review \u001b[39min\u001b[39;00m tqdm(dataset[\u001b[39m'\u001b[39m\u001b[39mreview\u001b[39m\u001b[39m'\u001b[39m])]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.64.18.48/home/adarsh/DLNLP/Assignment2.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX \u001b[39m=\u001b[39m [ torch\u001b[39m.\u001b[39mstack([ torch\u001b[39m.\u001b[39mtensor(token\u001b[39m.\u001b[39mvector) \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m doc ]) \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m tqdm(docs) ]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.64.18.48/home/adarsh/DLNLP/Assignment2.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mY \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(np\u001b[39m.\u001b[39mwhere(dataset[\u001b[39m'\u001b[39m\u001b[39msentiment\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnegative\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/adarsh/lib/python3.8/site-packages/spacy/language.py:1008\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[1;32m    988\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    989\u001b[0m     text: Union[\u001b[39mstr\u001b[39m, Doc],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    992\u001b[0m     component_cfg: Optional[Dict[\u001b[39mstr\u001b[39m, Dict[\u001b[39mstr\u001b[39m, Any]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    993\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Doc:\n\u001b[1;32m    994\u001b[0m     \u001b[39m\"\"\"Apply the pipeline to some text. The text can span multiple sentences,\u001b[39;00m\n\u001b[1;32m    995\u001b[0m \u001b[39m    and can contain arbitrary whitespace. Alignment into the original string\u001b[39;00m\n\u001b[1;32m    996\u001b[0m \u001b[39m    is preserved.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[39m    DOCS: https://spacy.io/api/language#call\u001b[39;00m\n\u001b[1;32m   1007\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1008\u001b[0m     doc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ensure_doc(text)\n\u001b[1;32m   1009\u001b[0m     \u001b[39mif\u001b[39;00m component_cfg \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1010\u001b[0m         component_cfg \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/anaconda3/envs/adarsh/lib/python3.8/site-packages/spacy/language.py:1099\u001b[0m, in \u001b[0;36mLanguage._ensure_doc\u001b[0;34m(self, doc_like)\u001b[0m\n\u001b[1;32m   1097\u001b[0m     \u001b[39mreturn\u001b[39;00m doc_like\n\u001b[1;32m   1098\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(doc_like, \u001b[39mstr\u001b[39m):\n\u001b[0;32m-> 1099\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmake_doc(doc_like)\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(doc_like, \u001b[39mbytes\u001b[39m):\n\u001b[1;32m   1101\u001b[0m     \u001b[39mreturn\u001b[39;00m Doc(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab)\u001b[39m.\u001b[39mfrom_bytes(doc_like)\n",
      "File \u001b[0;32m~/anaconda3/envs/adarsh/lib/python3.8/site-packages/spacy/language.py:1091\u001b[0m, in \u001b[0;36mLanguage.make_doc\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(text) \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_length:\n\u001b[1;32m   1088\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1089\u001b[0m         Errors\u001b[39m.\u001b[39mE088\u001b[39m.\u001b[39mformat(length\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(text), max_length\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_length)\n\u001b[1;32m   1090\u001b[0m     )\n\u001b[0;32m-> 1091\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenizer(text)\n",
      "File \u001b[0;32m~/anaconda3/envs/adarsh/lib/python3.8/site-packages/spacy/tokenizer.pyx:156\u001b[0m, in \u001b[0;36mspacy.tokenizer.Tokenizer.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/adarsh/lib/python3.8/site-packages/spacy/tokenizer.pyx:259\u001b[0m, in \u001b[0;36mspacy.tokenizer.Tokenizer._apply_special_cases\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/adarsh/lib/python3.8/site-packages/spacy/tokenizer.pyx:299\u001b[0m, in \u001b[0;36mspacy.tokenizer.Tokenizer._prepare_special_spans\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/adarsh/lib/python3.8/site-packages/spacy/tokens/doc.pyx:477\u001b[0m, in \u001b[0;36mspacy.tokens.doc.Doc.__getitem__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/adarsh/lib/python3.8/site-packages/spacy/util.py:1204\u001b[0m, in \u001b[0;36mnormalize_slice\u001b[0;34m(length, start, stop, step)\u001b[0m\n\u001b[1;32m   1200\u001b[0m             new_excs[new_key] \u001b[39m=\u001b[39m new_value\n\u001b[1;32m   1201\u001b[0m     \u001b[39mreturn\u001b[39;00m new_excs\n\u001b[0;32m-> 1204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnormalize_slice\u001b[39m(\n\u001b[1;32m   1205\u001b[0m     length: \u001b[39mint\u001b[39m, start: \u001b[39mint\u001b[39m, stop: \u001b[39mint\u001b[39m, step: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1206\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[\u001b[39mint\u001b[39m, \u001b[39mint\u001b[39m]:\n\u001b[1;32m   1207\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (step \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m step \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m   1208\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE057)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, filepath, nlp) -> None:\n",
    "        super(ReviewDataset, self).__init__()\n",
    "        self.nlp = nlp\n",
    "        dataset = pd.read_csv(filepath)\n",
    "        docs = [ nlp(review) for review in tqdm(dataset['review'])]\n",
    "        self.X = [ torch.stack([ torch.tensor(token.vector) for token in doc ]) for doc in tqdm(docs) ]\n",
    "        self.Y = torch.tensor(np.where(dataset['sentiment']=='negative', 0, 1))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index].cuda(), self.Y[index].cuda()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "dataset = ReviewDataset(filepath, nlp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentClassifier(torch.nn.Module):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super(RecurrentClassifier, self).__init__()\n",
    "        self.reccurrent = GRU(300, 300)\n",
    "        self.layers = ModuleList(\n",
    "            [\n",
    "                Linear(300, 100, True),\n",
    "                Linear(100, 1, True)\n",
    "            ]\n",
    "        )\n",
    "        self.h0 = torch.zeros((1,300)).cuda()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        _, h =self.reccurrent(input, self.h0)\n",
    "        return torch.sigmoid(self.layers[1](relu(self.layers[0](h[-1]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/adarsh/DLNLP/Assignment2.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.64.18.48/home/adarsh/DLNLP/Assignment2.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m train, valid \u001b[39m=\u001b[39m random_split(dataset, [\u001b[39mlen\u001b[39m(dataset)\u001b[39m-\u001b[39m\u001b[39mlen\u001b[39m(dataset)\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m10\u001b[39m , \u001b[39mlen\u001b[39m(dataset)\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m10\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.64.18.48/home/adarsh/DLNLP/Assignment2.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m dataloader \u001b[39m=\u001b[39m DataLoader(train, batch_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.64.18.48/home/adarsh/DLNLP/Assignment2.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m RecurrentClassifier()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "train, valid = random_split(dataset, [len(dataset)-len(dataset)//10 , len(dataset)//10])\n",
    "dataloader = DataLoader(train, batch_size=1)\n",
    "model = RecurrentClassifier()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 174/36000 [00:31<1:47:26,  5.56it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/adarsh/DLNLP/Assignment2.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.64.18.48/home/adarsh/DLNLP/Assignment2.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mwith\u001b[39;00m tqdm(dataloader) \u001b[39mas\u001b[39;00m tepoch:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.64.18.48/home/adarsh/DLNLP/Assignment2.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, (X, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tepoch):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.64.18.48/home/adarsh/DLNLP/Assignment2.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m         pred \u001b[39m=\u001b[39m model(X[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.64.18.48/home/adarsh/DLNLP/Assignment2.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m         \u001b[39mif\u001b[39;00m y:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.64.18.48/home/adarsh/DLNLP/Assignment2.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m             loss \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlog(pred)\n",
      "File \u001b[0;32m~/anaconda3/envs/adarsh/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/adarsh/DLNLP/Assignment2.ipynb Cell 6\u001b[0m in \u001b[0;36mRecurrentClassifier.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.64.18.48/home/adarsh/DLNLP/Assignment2.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.64.18.48/home/adarsh/DLNLP/Assignment2.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     _, h \u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreccurrent(\u001b[39minput\u001b[39;49m, torch\u001b[39m.\u001b[39;49mzeros((\u001b[39m1\u001b[39;49m,\u001b[39m300\u001b[39;49m)))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.64.18.48/home/adarsh/DLNLP/Assignment2.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39msigmoid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers[\u001b[39m1\u001b[39m](relu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers[\u001b[39m0\u001b[39m](h[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]))))\n",
      "File \u001b[0;32m~/anaconda3/envs/adarsh/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/adarsh/lib/python3.8/site-packages/torch/nn/modules/rnn.py:950\u001b[0m, in \u001b[0;36mGRU.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    949\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 950\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mgru(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[1;32m    951\u001b[0m                      \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[1;32m    952\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    953\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mgru(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[1;32m    954\u001b[0m                      \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optim = Adagrad(model.parameters())\n",
    "loss = 0\n",
    "losses = []\n",
    "batch_size = 500\n",
    "valid_x = [ for i in valid.indices]\n",
    "with tqdm(dataloader) as tepoch:\n",
    "    for i, (X, y) in enumerate(tepoch):\n",
    "        pred = model(X[0])\n",
    "        if y:\n",
    "            loss -= torch.log(pred)\n",
    "        else:\n",
    "            loss += torch.log(pred)\n",
    "        if (i+1)%batch_size==0:\n",
    "            \n",
    "            loss /= batch_size\n",
    "            \n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            pred = torch.stack([ model(x) for x, y in valid])\n",
    "            accuracy = (pred == dataset.Y[valid.indices]).sum().item()/pred.shape[0]\n",
    "            tepoch.set_postfix({'loss':loss.item(),'accuracy':accuracy})\n",
    "            tepoch.refresh()\n",
    "            losses.append(loss)\n",
    "            loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "x = range(1, len(losses)+1)\n",
    "y = torch.stack(losses).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.round(pred)\n",
    "pred = torch.reshape(pred,(pred.shape[0],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.495"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        ...,\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [-1.]], device='cuda:0', grad_fn=<RoundBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('adarsh': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "996adb597877041c5edd8d9ece12bc8d30466ad50ad58f1772dd77e49ff523c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
